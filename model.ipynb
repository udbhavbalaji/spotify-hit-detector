{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQasDyzalNU7"
      },
      "source": [
        "# CISC 372: Advanced Data Analytics\n",
        "## Project: Predicting whether a song has the potential to become a hit\n",
        "### Project Done By: Udbhav Balaji\n",
        "### Student Number: 20179467"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4f1bJsn-lNU9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        }
      ],
      "source": [
        "# importing the necessary libraries\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pickle\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3KLWeSoRlNU-"
      },
      "outputs": [],
      "source": [
        "# Reading in the 3 datasets\n",
        "data_90s = pd.read_csv('Datasets/dataset-of-90s.csv')\n",
        "data_00s = pd.read_csv('Datasets/dataset-of-10s.csv')\n",
        "data_10s = pd.read_csv('Datasets/dataset-of-10s.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxLEizRClNU_",
        "outputId": "f5971aaa-ab14-4c68-c16a-ad07d7f3e083"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "348004"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Since all the 3 datasets have the same columns, we can simply concatenate them together in order to create a master dataset\n",
        "master_data = pd.concat([data_90s, data_00s, data_10s], ignore_index=True, axis=0)\n",
        "master_data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D0dIRvMJlNVA"
      },
      "outputs": [],
      "source": [
        "# In order to avoid any bias due to time period, let's shuffle the rows so that their order is random\n",
        "master_data = shuffle(master_data)\n",
        "master_data.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRbvQOOglNVA",
        "outputId": "e906e356-0728-4067-98a4-47b0a5593d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18316 entries, 0 to 18315\n",
            "Data columns (total 19 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   track             18316 non-null  object \n",
            " 1   artist            18316 non-null  object \n",
            " 2   uri               18316 non-null  object \n",
            " 3   danceability      18316 non-null  float64\n",
            " 4   energy            18316 non-null  float64\n",
            " 5   key               18316 non-null  int64  \n",
            " 6   loudness          18316 non-null  float64\n",
            " 7   mode              18316 non-null  int64  \n",
            " 8   speechiness       18316 non-null  float64\n",
            " 9   acousticness      18316 non-null  float64\n",
            " 10  instrumentalness  18316 non-null  float64\n",
            " 11  liveness          18316 non-null  float64\n",
            " 12  valence           18316 non-null  float64\n",
            " 13  tempo             18316 non-null  float64\n",
            " 14  duration_ms       18316 non-null  int64  \n",
            " 15  time_signature    18316 non-null  int64  \n",
            " 16  chorus_hit        18316 non-null  float64\n",
            " 17  sections          18316 non-null  int64  \n",
            " 18  target            18316 non-null  int64  \n",
            "dtypes: float64(10), int64(6), object(3)\n",
            "memory usage: 2.7+ MB\n"
          ]
        }
      ],
      "source": [
        "master_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSjwIfKElNVB"
      },
      "source": [
        "Now that we have our master dataset in place, let's actually see what kind of information the dataset holds. We have the following features in the dataset:\n",
        "\n",
        "1. track - The name of the track\n",
        "2. artist - The name of the artist that made the track\n",
        "3. uri - The resource identifier of the track\n",
        "4. danceability - How danceable the track is (0.0 is lowest, 1.0 is highest)\n",
        "5. energy - How much energy does the track have (0.0 is the lowest, 1.0 is the highest)\n",
        "6. key - The estimated key of the track (0 = C, etc.)\n",
        "7. loudness - The overall loudness of the track in decibels (dB), Values range from -60 to 0 dB.\n",
        "8. mode - Indicates the modality of the track (whether the track is major or minor).\n",
        "9. speechiness - It represents the presence of spoken-words in the track. The more exclusively speech-like the recording of the song, the higher the value. (0.0 is the lowest, 1.0 is the highest).\n",
        "10. acousticness - A confidence metric from 0.0 to 1.0 of whether the track is acoustic. (0.0 is lowest confidence, 1.0 is the highest confidence)\n",
        "11. instrumentalness - Measure of how harmonized the vocals are (0.0 is the lowest, 1.0 is the highest).\n",
        "12. liveness - detects confidence about whether the song was recorded in the presence of a live audience.\n",
        "13. valence - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.\n",
        "14. tempo - overall estimated tempo of the track in Beats Per Minute (BPM).\n",
        "15. duration_ms - The duration of the track in milliseconds.\n",
        "16. time_signature - The estimated overall time signature of the track. (Conventional measure of how many beats are in one bar).\n",
        "17. chorus_hit - The estimated timestamp when the chorus will hit. It has been assumed that the chorus of every song begins at the 3rd section of the song.\n",
        "18. sections - The number of sections that a track has. \n",
        "19. target - This is the target feature. '1' implies that it is a 'flop', 0 implies it is a 'flop'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmU0-G1xlNVC",
        "outputId": "64c906a6-7e9e-4a14-f499-c9d62cb56d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11915 entries, 0 to 18311\n",
            "Data columns (total 19 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   track             11915 non-null  object \n",
            " 1   artist            11915 non-null  object \n",
            " 2   uri               11915 non-null  object \n",
            " 3   danceability      11915 non-null  float64\n",
            " 4   energy            11915 non-null  float64\n",
            " 5   key               11915 non-null  int64  \n",
            " 6   loudness          11915 non-null  float64\n",
            " 7   mode              11915 non-null  int64  \n",
            " 8   speechiness       11915 non-null  float64\n",
            " 9   acousticness      11915 non-null  float64\n",
            " 10  instrumentalness  11915 non-null  float64\n",
            " 11  liveness          11915 non-null  float64\n",
            " 12  valence           11915 non-null  float64\n",
            " 13  tempo             11915 non-null  float64\n",
            " 14  duration_ms       11915 non-null  int64  \n",
            " 15  time_signature    11915 non-null  int64  \n",
            " 16  chorus_hit        11915 non-null  float64\n",
            " 17  sections          11915 non-null  int64  \n",
            " 18  target            11915 non-null  int64  \n",
            "dtypes: float64(10), int64(6), object(3)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "# Dropping duplicate rows, if any, from the master dataset\n",
        "master_data.drop_duplicates(keep='first', inplace=True)\n",
        "master_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7N67r1mjlNVD"
      },
      "outputs": [],
      "source": [
        "# Separating the dataset from the target variable\n",
        "X = master_data.drop(labels='target', axis=1, inplace=False)\n",
        "y = master_data.target\n",
        "\n",
        "# Splitting our dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7SHCl1uZlNVD"
      },
      "outputs": [],
      "source": [
        "# Gathering all numeric features together\n",
        "numeric_features = [\n",
        "    'danceability','energy','loudness','speechiness','acousticness',\n",
        "    'instrumentalness','liveness','valence','tempo','duration_ms','chorus_hit','sections'\n",
        "            ]\n",
        "\n",
        "# Gathering all categorical features together\n",
        "categorical_features = [\n",
        "    'artist','key','mode','time_signature'\n",
        "]\n",
        "\n",
        "# Creating the numeric preprocessing pipeline to feed our ML model\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Creating the categorical preprocessing pipeline to feed our ML model\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Creating the column transpformer \n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzpU95ZmpRhe"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lGeqXzzJlNVE"
      },
      "outputs": [],
      "source": [
        "# First, let's try using Logistic Regression\n",
        "clf_log = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Defining the param grid that we want to test using CV\n",
        "param_grid_log = {\n",
        "    'clf__penalty': ['l2'],\n",
        "    # 'clf__dual': [True, False],\n",
        "    'clf__fit_intercept': [True, False],\n",
        "    'clf__class_weight': ['balanced', None],\n",
        "    'clf__solver': ['newton-cg','lbfgs','liblinear','sag','saga']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SOSSvRI8lNVE"
      },
      "outputs": [],
      "source": [
        "# Applying the transformations to the data (both training and testing sets)\n",
        "X_train = X_train[[*numeric_features, *categorical_features]]\n",
        "X_test = X_test[[*numeric_features, *categorical_features]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYiGckzhlNVF",
        "outputId": "896c4217-946e-41d0-9616-8a7e285477f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.836 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.793 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.811 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.792 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.801 total time=   0.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.836 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.793 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.811 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.792 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.803 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=liblinear;, score=0.848 total time=   0.0s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=liblinear;, score=0.808 total time=   0.0s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=liblinear;, score=0.821 total time=   0.0s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=liblinear;, score=0.806 total time=   0.0s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=liblinear;, score=0.824 total time=   0.0s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=liblinear;, score=0.848 total time=   0.0s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=liblinear;, score=0.808 total time=   0.0s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=liblinear;, score=0.821 total time=   0.0s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=liblinear;, score=0.806 total time=   0.0s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=liblinear;, score=0.825 total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END clf__class_weight=None, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.832 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=None, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.792 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=None, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.810 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=None, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.811 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=None, clf__fit_intercept=False, clf__penalty=l2, clf__solver=saga;, score=0.796 total time=   0.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.834 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.792 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.796 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.810 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=saga;, score=0.810 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=newton-cg;, score=0.848 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=newton-cg;, score=0.821 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=newton-cg;, score=0.808 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=newton-cg;, score=0.806 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=False, clf__penalty=l2, clf__solver=newton-cg;, score=0.824 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.801 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.841 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.817 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.801 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=newton-cg;, score=0.848 total time=   0.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END clf__class_weight=None, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.819 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=newton-cg;, score=0.808 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=newton-cg;, score=0.821 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=newton-cg;, score=0.826 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=newton-cg;, score=0.806 total time=   0.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.843 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.804 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.801 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.820 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__fit_intercept=True, clf__penalty=l2, clf__solver=sag;, score=0.822 total time=   0.1s\n",
            "Best Score = 0.8217696029460736\n"
          ]
        }
      ],
      "source": [
        "# Performing RandomizedSearchCV to perform hyper-parameter tuning of the Logistic Regression model\n",
        "random_log = RandomizedSearchCV(\n",
        "    clf_log, param_grid_log, cv=5, verbose=3,\n",
        "    n_jobs=2, scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fitting the training data to the model\n",
        "random_log.fit(X_train, y_train)\n",
        "\n",
        "# Getting the best possible model\n",
        "print(f'Best Score = {random_log.best_score_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MvjJnS6ma6n",
        "outputId": "151e4380-86bd-429d-bf95-f00db41764d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy: 83.15549694281262 %\n"
          ]
        }
      ],
      "source": [
        "# Testing the model on the testing set\n",
        "y_pred = random_log.predict(X_test)\n",
        "\n",
        "# Getting the accuracy of the model\n",
        "conf_mat = confusion_matrix(y_pred, y_test)\n",
        "acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "print('Overall accuracy: {} %'.format(acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX9MCWFlpj7e"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PAyNIlLopnqm"
      },
      "outputs": [],
      "source": [
        "clf_rf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "param_grid_rf = {\n",
        "    'clf__n_estimators': [20,50,100,200],\n",
        "    'clf__criterion': ['gini','entropy'],\n",
        "    'clf__max_depth': [20,50],\n",
        "    'clf__max_features': ['auto','sqrt','log2'],\n",
        "    'clf__class_weight': ['balanced','balanced_subsample']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.807 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.782 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.811 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.793 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.805 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.772 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.801 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.789 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.792 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=50;, score=0.822 total time=   0.2s\n",
            "[CV 5/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=20;, score=0.800 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=50;, score=0.810 total time=   0.2s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=50;, score=0.787 total time=   0.2s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=50;, score=0.811 total time=   0.2s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=50;, score=0.818 total time=   0.2s\n",
            "[CV 2/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=100;, score=0.796 total time=   0.3s\n",
            "[CV 1/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=100;, score=0.801 total time=   0.3s\n",
            "[CV 3/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=100;, score=0.776 total time=   0.3s\n",
            "[CV 4/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=100;, score=0.808 total time=   0.3s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=20;, score=0.790 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=20;, score=0.745 total time=   0.1s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=20;, score=0.727 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=20;, score=0.769 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=100;, score=0.772 total time=   0.3s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=log2, clf__n_estimators=20;, score=0.762 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=200;, score=0.813 total time=   1.5s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=200;, score=0.824 total time=   1.5s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=200;, score=0.821 total time=   1.5s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=200;, score=0.831 total time=   1.5s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=auto, clf__n_estimators=50;, score=0.815 total time=   0.2s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=auto, clf__n_estimators=50;, score=0.794 total time=   0.2s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=auto, clf__n_estimators=50;, score=0.797 total time=   0.2s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=auto, clf__n_estimators=50;, score=0.814 total time=   0.2s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=auto, clf__n_estimators=50;, score=0.801 total time=   0.3s\n",
            "[CV 1/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=100;, score=0.820 total time=   0.4s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=200;, score=0.824 total time=   1.6s\n",
            "[CV 2/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=100;, score=0.806 total time=   0.4s\n",
            "[CV 4/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=100;, score=0.825 total time=   0.5s\n",
            "[CV 3/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=100;, score=0.821 total time=   0.4s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=sqrt, clf__n_estimators=20;, score=0.814 total time=   0.1s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=sqrt, clf__n_estimators=20;, score=0.771 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced_subsample, clf__criterion=gini, clf__max_depth=50, clf__max_features=log2, clf__n_estimators=100;, score=0.812 total time=   0.5s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=sqrt, clf__n_estimators=20;, score=0.796 total time=   0.1s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=sqrt, clf__n_estimators=20;, score=0.798 total time=   0.1s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=entropy, clf__max_depth=20, clf__max_features=sqrt, clf__n_estimators=20;, score=0.799 total time=   0.1s\n",
            "[CV 1/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=20;, score=0.811 total time=   0.2s\n",
            "[CV 2/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=20;, score=0.818 total time=   0.2s\n",
            "[CV 3/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=20;, score=0.807 total time=   0.2s\n",
            "[CV 4/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=20;, score=0.827 total time=   0.2s\n",
            "[CV 5/5] END clf__class_weight=balanced, clf__criterion=gini, clf__max_depth=50, clf__max_features=sqrt, clf__n_estimators=20;, score=0.821 total time=   0.2s\n",
            "Best score = 0.8223282599753189\n"
          ]
        }
      ],
      "source": [
        "random_rf = RandomizedSearchCV(\n",
        "    clf_rf, param_grid_rf, cv=5, n_jobs=2, \n",
        "    verbose=3, scoring='accuracy'\n",
        ")\n",
        "\n",
        "random_rf.fit(X_train, y_train)\n",
        "\n",
        "print(f'Best score = {random_rf.best_score_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy: 83.40726531590936 %\n"
          ]
        }
      ],
      "source": [
        "# Testing the model on the testing set\n",
        "y_pred = random_rf.predict(X_test)\n",
        "\n",
        "# Getting the accuracy of the model\n",
        "conf_mat = confusion_matrix(y_pred, y_test)\n",
        "acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "print('Overall accuracy: {} %'.format(acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_xg = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('clf', XGBClassifier(verbose=0))\n",
        "])\n",
        "\n",
        "param_grid_xg = {\n",
        "    'clf__n_estimators': [10,20,50,100,200],\n",
        "    'clf__max_depth': [10,20,30],\n",
        "    'clf__learning_rate': [0.1,0.001,0.001],\n",
        "    'clf__objective': ['binary:logistic','reg:squarederror'],\n",
        "    'clf__booster': ['gbtree','gblinear']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:04:56] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:04:56] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:04:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:04:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:04:58] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:04:58] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:04:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:04:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:04:59] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:04:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:04:59] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:04:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:01] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:06] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:08] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:13] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:14] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:14] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:14] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:14] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:14] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:15] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:15] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:16] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:16] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:17] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:17] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:18] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:19] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:19] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:21] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:22] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:22] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:22] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:25] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:25] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:29] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:30] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:30] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:30] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:30] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/spotify/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21:05:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "[21:05:32] WARNING: ../src/learner.cc:576: \n",
            "Parameters: { \"max_depth\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[21:05:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "Best score = 0.8659748095042212\n"
          ]
        }
      ],
      "source": [
        "random_xg = RandomizedSearchCV(\n",
        "    clf_xg, param_grid_xg, cv=5, n_jobs=2,\n",
        "    verbose=0, scoring='accuracy'\n",
        ")\n",
        "\n",
        "random_xg.fit(X_train, y_train)\n",
        "\n",
        "print(f'Best score = {random_xg.best_score_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best score = 0.8659748095042212\n"
          ]
        }
      ],
      "source": [
        "print(f'Best score = {random_xg.best_score_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy: 88.15489749430525 %\n"
          ]
        }
      ],
      "source": [
        "# Testing the model on the testing set\n",
        "y_pred = random_xg.predict(X_test)\n",
        "\n",
        "# Getting the accuracy of the model\n",
        "conf_mat = confusion_matrix(y_pred, y_test)\n",
        "acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "print('Overall accuracy: {} %'.format(acc*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a model that has quite a good result in terms of generalizing to new data, let's serialize the model and store it in a pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storing the XGB model as a pickle file to use in our application\n",
        "filename = 'model.pkl'\n",
        "pickle.dump(random_xg, open(filename, 'wb'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b78bfe9a4cc8588c2cff02bb17ba264cc3b6173d3e5934fabeee3cf1d784438c"
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 ('spotify')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
